Lone Star Ruby Conference 2010, Aug 26–28

*Glenn Vanderburg*


Real Software Engineering
=========================
[video](http://www.youtube.com/watch?v=NP9AIUT9nos)
. [slides](http://cdn.oreillystatic.com/en/assets/1/event/40/Real%20Software%20Engineering%20Presentation.pdf)

Software engineering as it's taught in universities simply doesn't work. It
doesn't produce software systems of high quality, and it doesn't produce them
for low cost. Sometimes, even when practiced rigorously, it doesn't produce
systems at all.

That's odd, because in every other field, the term "engineering" is reserved
for methods that work.

What then, does real software engineering look like? How can we consistently
deliver high-quality systems to our customers and employers in a timely fashion
and for a reasonable cost? In this session, we'll discuss where software
engineering went wrong, and build the case that disciplined Agile methods, far
from being "anti-engineering" (as they are often described), actually represent
the best of engineering principles applied to the task of software development.


## Verbatim

Good morning! I'm Glenn Vanderburg, I work for InfoEther with [Rich Kilmer]
(https://www.wikiwand.com/en/Richard_Kilmer) and [Chad
Fowler](http://chadfowler.com/about/) and [Bruce
Williams](https://www.linkedin.com/in/wbruce) whom I suspect a lot of you know
here. And I'm here to talk about real software engineering. I've been at all
four out of Lone Star Ruby Confs and really enjoy them. So to start off with...

#### Software engineering doesn't work

Software engineering doesn't work... At least as it's currently taught in
universities and in training programs in companies if you happen to work for
one of the few companies that care about teaching such things. The techniques
that are taught and that are called "software engineering" simply don't work.
They don't reliably control costs. They don't reliably produce quality
software. Sometimes even when they're practiced rigorously by people who've
been trained to do so, they don't produce working software at all.

And that shouldn't really be suprising to any of us, because this seems to be
common knowledge among working programmers, all over this country at least...
But well... it's not surprising it is odd. Because in every other field that
aspires to the title of an engineering discipline the term "engineering" is
reserved for practices that work. In fact that's as good a capsule definition
of engineering independent of any particular discipline as you're likely to
find which is the set of practices and techniques that have been determined to
work reliably through experience. And yet in software we have this set of
practices that don't work and we call *that* engineering.

Now this is caused a lot of discussion, especially over the past year or so,
about whether software is really an engineering discipline at all and whether
software development really doesn't fit that metaphor. It's not engineering,
it's more like a craft or an art or something else or gardening or moviemaking
or various different analogies I've heard. And maybe engineering is just an
inappropriate metaphor for the task of building software. And I don't think
that's true. I do think software is an art, I do think it's a craft, I do think
it is in some respects a science. But that doesn't mean it can't also be
engineering. I say that the problem is that the people who have defined the set
of desciplines that we call "software engineering" have misunderstood two very
important things — software and engineering. And that has resulted in software
engineering being a caricature of an engineering descipline.

So I'm going to explain what I mean by this. And to do so I need first to start
off by explaining what I mean when I say that software is a caricature of
engineering and kind of how it got to be that way. And then I need to explain
what real engineering looks like. How many people in the room were trained as
engineers, not as software developers? Okay, intersting. I'm especially
intrested in feedback from people who have more of a classical engineering
background. Because I don't. I've had to kind of learn all this on my own. But
I think I've come to a pretty good understanding of where software engineering
got it wrong.

And then we're going to look at what real software development looks like. And
in the middle somewhere, I think, we can develop a picture of what real
software engineering is.

#### A Caricature of Engineering

So, the first time that the term "software engineering" really got bandied
about a lot was in 1968 at a conference in Garmisch, Germany, organised by
NATO, above all things. The first conference on software engineering sponsored
by the NATO science committee and at this time, you know, people were dealing
with what was called "the software crisis" and software projects were really
unreliable, and flaky, and error-prone, and failure-prone, and had huge cost
overruns. And people really didn't know much about how to manage them. So they
said: "You know, we need to kind of grow up as a discipline and as a field and
start becoming an engineering descipline." and so they had this conference.

I've known about and heard about this conference for many many years and never
really knew any details about it. And since I've got interested in this topic
I went and read the proceedings that are all online. And I was expecting to
find "ok, this is where the madness started". And in fact, no. I didn't find
that at all. The participants in this conference were by and large really smart
people who were working software developers. There are few academics, but the
academics had good things to say as well. And by and large the findings of this
conference were entirely reasonable and reflected a great deal of wisdom about
software and its state at the time. In fact mostly what you'll be impressed by
as you go there and read those proceedings if you do, is how willing they were
to admit that they didn't know anything. The conference is full of: "You know,
we're just kind of babes in the woods at this. It's a new field. It's different
from other fields before. There's all kind of stuff we don't know. We kind of
*think*, it might be like this." There is a lot of uncertainty.

[Alan Perlis](https://www.wikiwand.com/en/Alan_Perlis) gave a talk in which at
the end of the conference he sort of summarized the few things that the group
was able to all agree on about what software as engineering should look like.
The first of the three things were:

>   1) A software system can best be designed if the testing
>      is interlaced with the designing instead of being
>      used after the design.

That's pretty reasonable by our standards. Number two:

>   2) A simulation that matches the requirements contains
>      the control which organizes the design of the system.

Now the terminology has evolved since then, so that doesn't immediately seem
to make a lot of sense, but I think if you combine that with the third one, it
is clear what he means:

>   3) Through successive repetitions of this process of interlaced testing
>      and design the model ultimately becomes the software system itself.
>      [...] in effect the testing and the replacement of simulations with
>      modules that are deeper and more detailed goes on with the simulation
>      model controlling, as it were, the place and order in which these
>      things are done.

He was talking about [unit testing](https://www.wikiwand.com/en/Unit_testing),
and [mocking](http://www.wikiwand.com/en/Mock_object), and [iterative design
and development](https://www.wikiwand.com/en/Iterative_and_incremental_development).
Pretty reasonable.

There was a second NATO software engineering conference a year later. The tone
of those proceedings are entirely different. During that year everything went
wrong. Within that year software engineering turned into what it was for many
many years which is an entire field of processes designed in academia for
practitioners. What went wrong in one year? Well, I don't know. I was alive
then, but I wasn't a computer programmer back then. And so I wasn't involved in
these processes. But I have a theory of what went wrong. And I can illustrate
that theory by talking another place where some very reasonable statements were
misconstrued and turned into completely unreasonable conclusions. Well, we know
what happened and that is the birth of the [waterfall
process](http://www.wikiwand.com/en/Waterfall_model).

Waterfall was introduced by [Winston Royce](https://www.wikiwand.com/en/Winston_W._Royce)
in a paper at IEEE WESCON in 1970. And the paper was called ["Managing the
development of large software systems"](http://www.serena.com/docs/agile/papers/Managing-The-Development-of-Large-Software-Systems.pdf).
And Royce spent the rest of his career running around saying: "No-no-no, I
didn't mean that, I was misquoted." And I've heard that story too. And when I
went back and read this paper, I was astonished to find... you know... I wasn't
suprised to find that he was telling the truth—he really didn't recommend
waterfall. But what I realized was that the reason that people thought he was
recomending waterfall is that this paper is a marvel of bad information design.
If you wanted study how to write a paper that conveys exactly the opposite
impression from what you are trying to get across, you couldn't do better than
to go read this paper.

Let's take a look at this for a minute and assume that you're a manager of
a group producing software in 1970. And you're struggling with how to, you
know, reliably estimate and produce stuff that works—on all these problems that
have plagued software management since the beginning. And a friend or colleague
or maybe one of your employees drops this paper on your desk and says: "This
might help". Oh, "Managing the development of large software systems". That's
pretty good, that's what I'm intrested in. And oh I see that there's a diagram
there on the front page. So you know, let's start by kinda looking at the
diagram to see what this is about—skim it first and then read. So that diagram
says you may start with analysis and then you go to coding. And that's a kinda
simplistic. And even I know that's kinda simplistic. So before I waste time
reading this paper I'm going to look at the rest of the diagrams and see if
this guy has a brain in his head or not. And so at the top of the second page
I see this. This is the first time the classic waterfall diagram ever appeared.
And you know, well, that's pretty good. System requirements and from that you
get software requirements, and then you move to analysis, and design, coding,
testing and operations. And look at the caption there:

>   Implementation steps to develop a large computer program
>   for delivery to a customer.

I can understand that process. That makes sense to me. I see how all those
things work. And I get this metting to go to. I've got what I need out of that.

With the very next line:

>   I believe in this concept, but the implementation described above
>   is risky and invites failure.

The funny thing is that that sense describes figure 3, which is on the next
page. To find out what Winston Royce has to say about figure 2 you have to
go back to the first page where he says:

>   An implementation plan [...] keyed only to these steps is doomed.

Well, let's be optimistic and assume that the manager comes back from his
meeting and picks up the paper again, and tries to continue through it. And he
flips to the 3rd page and he sees this.

To our eyes that looks a little more reasonable. We can see feedback coming
from later steps to influence earlier steps, as you learn more, as you get down
into the details. And then Royce goes on to say that the feedback isn't even
that localized. And sometimes, you know, the things you learn in testing have
to go all the way back up and affect the software requirements... And this is
starting to seem confusing, and messy, and hard to control... And well, whoa...
ah, gee... I don't know what this means. And always black boxes... And it just
gets worse and worse. And then the final diagram which is helpfully labeled
"Summary"... Eh, I think I'll go back to that one.

And within just a few years waterfall was an established standard in the
industry. And it's easy to kick waterfall in its kind of... Well, most people
have realized that's not the way to do things, but I've run into groups that
kinda religiously follow waterfall and don't see how anything else could
possibly work as recently as 3 or 4 years ago. And as recently as late 90's the
Department of Defense was still essentially mandating waterfall for all of the
projects that they paid for. It has taken a long time for this idea, which was
presented as a way of doing things that was obviously doomed, to finally sort
of work its way out of people's consciousness. Because people like simple
solutions. And they hear terms and map those terms to things they already
understand (or think they understand), and latch onto that and run with it
without thinking very carefully. That's just charteristic of people and
it happend with waterfall and, I think, it alse happened with this term
"software engineering". H. L. Mencken said:

>   For every complex problem there is a solution
>   that is simple, neat, and wrong.

That certainly applies there.

Later software engineering even as people began understanding the weaknesses of
waterfall and moving beyound it—later software engineering shared a bias with
the waterfall model, which is an attachment to what's called the *defined
process model*. This is a description of that model from [Schwaber and Beedle's
book on scrum](https://books.google.ru/books?id=BpFYAAAAYAAJ):

>   The *defined process control model* requires that every piece of work be
>   completely understood. A defined process can be started and allowed to run
>   until completion, with the same results every time.

The idea of process models was introduced by some chemical engineering
researchers.







Videos of [Boeing 777](http://www.youtube.com/watch?v=Ai2HmvAXcU0) and
[Boeing 787](http://www.youtube.com/watch?v=sA9Kato1CxA) wing break tests.
